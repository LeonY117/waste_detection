{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FRCNN0.0.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1m4ydCAfVmY-1z8JCa6HIcb8QB0aU_C2x","authorship_tag":"ABX9TyOIYW/GbzzsbzZjfj02tHKv"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"aopcLPbg0Fwq"},"source":["### About \n","\n","The purpose of this notebook is to experiment & have a working training workflow:\n","\n","* make changes to data \n","* make TFRecordDataset\n","* get model weights and configuration file\n","* change configuration file\n","* train and pray \n","\n"]},{"cell_type":"markdown","metadata":{"id":"t1WsJFNc0jO8"},"source":["### Loading modules & importing dataset "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3KjH3CLQlIyT","executionInfo":{"status":"ok","timestamp":1611486445872,"user_tz":0,"elapsed":26881,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}},"outputId":"f78506e7-cf83-4c53-95be-7d8f90fa8dca"},"source":["# Install modules\n","!pip install -q Cython contextlib2 pycocotools tf_slim\n","!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n","\n","# Used for rotation\n","!pip install -q -U tensorflow-addons"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 358kB 5.5MB/s \n","\u001b[?25hSelecting previously unselected package python-bs4.\n","(Reading database ... 146374 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.3_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.4_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.3) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1ubuntu0.4) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","\u001b[K     |████████████████████████████████| 706kB 5.2MB/s \n","\u001b[?25h"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHTDIR7z7F7B","executionInfo":{"status":"ok","timestamp":1611486649274,"user_tz":0,"elapsed":4484,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}},"outputId":"210f5aa2-1f02-41ff-be05-cc090f9a1b6a"},"source":["%cd /content\n","!git clone --quiet https://github.com/tensorflow/models.git\n","\n","%cd /content/models/research\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","import os\n","os.environ['PYTHONPATH'] += ':/content/models:/content/models/research/:/content/models/research/slim/'\n","import sys\n","sys.path.append(\"/content/models\")\n","\n","!python object_detection/builders/model_builder_test.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","fatal: destination path 'models' already exists and is not an empty directory.\n","/content/models/research\n","2021-01-24 11:10:45.806544: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x2u-3cSsEzyM"},"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import os\n","import shutil\n","import json\n","import random\n","import re\n","import io\n","import imageio\n","import cv2\n","import glob\n","import scipy.misc\n","import math\n","import numpy as np\n","import tensorflow_addons as tfa\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from IPython.display import display, Javascript\n","from IPython.display import Image as IPyImage\n","\n","import tensorflow as tf\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import config_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.utils import colab_utils\n","from object_detection.builders import model_builder\n","\n","import tensorflow_hub as hub\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GoVMRU5f8qe5"},"source":["# 'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","# 'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","# 'batch_size': 12\n","\n","#/content/models/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8.config\n","# /content/models/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dzboZeOfEmHe"},"source":["### Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJzWndOxLUOZ","executionInfo":{"status":"ok","timestamp":1611488231931,"user_tz":0,"elapsed":1808,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}},"outputId":"818e644d-1e4c-4fef-a585-6a3235dd2d25"},"source":["%cd /content/data\n","!curl -L \"https://app.roboflow.com/ds/PzLODKbsNY?key=Zu2TglfXnL\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/data\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   891  100   891    0     0   1323      0 --:--:-- --:--:-- --:--:--  1321\n","100 17.5M  100 17.5M    0     0  17.7M      0 --:--:-- --:--:-- --:--:-- 17.7M\n","Archive:  roboflow.zip\n"," extracting: README.roboflow.txt     \n","   creating: test/\n"," extracting: test/wastes.tfrecord    \n"," extracting: test/wastes_label_map.pbtxt  \n","   creating: train/\n"," extracting: train/wastes.tfrecord   \n"," extracting: train/wastes_label_map.pbtxt  \n","   creating: valid/\n"," extracting: valid/wastes.tfrecord   \n"," extracting: valid/wastes_label_map.pbtxt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JR7lKNA3LApR"},"source":["test_record_fname = '/content/data/valid/wastes.tfrecord'\n","train_record_fname = '/content/data/train/wastes.tfrecord'\n","label_map_pbtxt_fname = '/content/data/train/wastes_label_map.pbtxt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WyrmUYCMgre","executionInfo":{"status":"ok","timestamp":1611492197417,"user_tz":0,"elapsed":550,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}}},"source":["MODEL = 'faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8'\n","pipeline_file = 'faster_rcnn_resnet152_coco.config'\n","batch_size = 12\n","\n","# /content/models/research/faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz"],"execution_count":119,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EHmgm6KiMXgx","executionInfo":{"status":"ok","timestamp":1611492276329,"user_tz":0,"elapsed":11070,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}},"outputId":"13d8df04-e186-494d-df76-3d4d6c89c317"},"source":["%cd /content/models/research\n","# /content/drive/MyDrive/waste_detection/Leon/pre_trained_weights/faster_rcnn_inception_resnet_v2_640x640_coco17_tpu-8.tar.gz\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","DEST_DIR = '/content/models/research/pretrained_model'\n","\n","# if not (os.path.exists(MODEL_FILE)):\n","#     urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","!cp \"/content/drive/MyDrive/waste_detection/Leon/pre_trained_weights/faster_rcnn_resnet152_v1_1024x1024_coco17_tpu-8.tar.gz\" .\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","    shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)"],"execution_count":121,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SuT1pboYNCQP","executionInfo":{"status":"ok","timestamp":1611492283258,"user_tz":0,"elapsed":803,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}},"outputId":"e659c3a4-91cc-4816-bb44-971b926b7e02"},"source":["!echo {DEST_DIR}\n","!ls -alh {DEST_DIR}"],"execution_count":122,"outputs":[{"output_type":"stream","text":["/content/models/research/pretrained_model\n","total 20K\n","drwxr-x---  4 345018 89939 4.0K Jul 11  2020 .\n","drwxr-xr-x 27 root   root  4.0K Jan 24 12:44 ..\n","drwxr-x---  2 345018 89939 4.0K Jul 10  2020 checkpoint\n","-rw-r-----  1 345018 89939 3.7K Jul 11  2020 pipeline.config\n","drwxr-x---  3 345018 89939 4.0K Jul 10  2020 saved_model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"HVB5GXRqNDdV","executionInfo":{"status":"ok","timestamp":1611492284463,"user_tz":0,"elapsed":489,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}},"outputId":"9002b719-7165-4a3f-f55e-93c7ed43f4b7"},"source":["fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint"],"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/models/research/pretrained_model/model.ckpt'"]},"metadata":{"tags":[]},"execution_count":123}]},{"cell_type":"code","metadata":{"id":"M7htKTmvNF7A","executionInfo":{"status":"ok","timestamp":1611492286651,"user_tz":0,"elapsed":484,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}}},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":124,"outputs":[]},{"cell_type":"code","metadata":{"id":"2FFmXLVONLtD","executionInfo":{"status":"ok","timestamp":1611492288278,"user_tz":0,"elapsed":470,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":125,"outputs":[]},{"cell_type":"code","metadata":{"id":"lnl64iwPNMgP","executionInfo":{"status":"ok","timestamp":1611492291390,"user_tz":0,"elapsed":521,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}}},"source":["import re\n","num_steps = int(1000)\n","num_eval_steps = 50\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # tfrecord files train and test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Set training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n","\n","    # Set training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {:d}'.format(num_steps), s)\n","    \n","    # Set number of classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":126,"outputs":[]},{"cell_type":"code","metadata":{"id":"-sZyF-dURxvk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u46G6DqeNWcQ","executionInfo":{"status":"ok","timestamp":1611492293919,"user_tz":0,"elapsed":507,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}},"outputId":"1dde6f33-0363-4d3d-d923-e397616fe270"},"source":["!cat {pipeline_fname}"],"execution_count":127,"outputs":[{"output_type":"stream","text":["# Faster R-CNN with Resnet-152 (v1), configuration for MSCOCO Dataset.\n","# Users should configure the fine_tune_checkpoint field in the train config as\n","# well as the label_map_path and input_path fields in the train_input_reader and\n","# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n","# should be configured.\n","\n","model {\n","  faster_rcnn {\n","    num_classes: 10\n","    image_resizer {\n","      keep_aspect_ratio_resizer {\n","        min_dimension: 600\n","        max_dimension: 1024\n","      }\n","    }\n","    feature_extractor {\n","      type: 'faster_rcnn_resnet152'\n","      first_stage_features_stride: 16\n","    }\n","    first_stage_anchor_generator {\n","      grid_anchor_generator {\n","        scales: [0.25, 0.5, 1.0, 2.0]\n","        aspect_ratios: [0.5, 1.0, 2.0]\n","        height_stride: 16\n","        width_stride: 16\n","      }\n","    }\n","    first_stage_box_predictor_conv_hyperparams {\n","      op: CONV\n","      regularizer {\n","        l2_regularizer {\n","          weight: 0.0\n","        }\n","      }\n","      initializer {\n","        truncated_normal_initializer {\n","          stddev: 0.01\n","        }\n","      }\n","    }\n","    first_stage_nms_score_threshold: 0.0\n","    first_stage_nms_iou_threshold: 0.7\n","    first_stage_max_proposals: 300\n","    first_stage_localization_loss_weight: 2.0\n","    first_stage_objectness_loss_weight: 1.0\n","    initial_crop_size: 14\n","    maxpool_kernel_size: 2\n","    maxpool_stride: 2\n","    second_stage_box_predictor {\n","      mask_rcnn_box_predictor {\n","        use_dropout: false\n","        dropout_keep_probability: 1.0\n","        fc_hyperparams {\n","          op: FC\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.0\n","            }\n","          }\n","          initializer {\n","            variance_scaling_initializer {\n","              factor: 1.0\n","              uniform: true\n","              mode: FAN_AVG\n","            }\n","          }\n","        }\n","      }\n","    }\n","    second_stage_post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 0.0\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 300\n","      }\n","      score_converter: SOFTMAX\n","    }\n","    second_stage_localization_loss_weight: 2.0\n","    second_stage_classification_loss_weight: 1.0\n","  }\n","}\n","\n","train_config: {\n","  batch_size: 12\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        manual_step_learning_rate {\n","          initial_learning_rate: 0.0003\n","          schedule {\n","            step: 900000\n","            learning_rate: .00003\n","          }\n","          schedule {\n","            step: 1200000\n","            learning_rate: .000003\n","          }\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  gradient_clipping_by_norm: 10.0\n","  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n","  from_detection_checkpoint: true\n","  # Note: The below line limits the training process to 200K steps, which we\n","  # empirically found to be sufficient enough to train the pets dataset. This\n","  # effectively bypasses the learning rate schedule (the learning rate will\n","  # never decay). Remove the below line to train indefinitely.\n","  num_steps: 1000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","}\n","\n","train_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/data/train/wastes.tfrecord\"\n","  }\n","  label_map_path: \"/content/data/train/wastes_label_map.pbtxt\"\n","}\n","\n","eval_config: {\n","  num_examples: 8000\n","  # Note: The below line limits the evaluation process to 10 evaluations.\n","  # Remove the below line to evaluate indefinitely.\n","  max_evals: 10\n","}\n","\n","eval_input_reader: {\n","  tf_record_input_reader {\n","    input_path: \"/content/data/valid/wastes.tfrecord\"\n","  }\n","  label_map_path: \"/content/data/train/wastes_label_map.pbtxt\"\n","  shuffle: false\n","  num_readers: 1\n","}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X29-Cok1NnIv","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1611492350556,"user_tz":0,"elapsed":581,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}},"outputId":"c3b599cf-f63a-4793-d0b8-5485cff11917"},"source":["pipeline_fname"],"execution_count":130,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/models/research/object_detection/samples/configs/faster_rcnn_resnet152_coco.config'"]},"metadata":{"tags":[]},"execution_count":130}]},{"cell_type":"markdown","metadata":{"id":"fZ847GrVNnYr"},"source":["### Train"]},{"cell_type":"code","metadata":{"id":"a4ixjwk6Np4z"},"source":["!pip install lvis"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yC1tS96rNrHl","executionInfo":{"status":"ok","timestamp":1611492363625,"user_tz":0,"elapsed":4623,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}},"outputId":"054ddfbd-bad0-43d4-bac9-d5983f8cae42"},"source":["!python /content/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path='/content/models/research/object_detection/samples/configs/faster_rcnn_resnet152_coco.config' \\\n","    --model_dir={model_dir} \\\n","    --alsologtostderr \\\n","    --num_train_steps=1000 \\\n","    --num_eval_steps=50"],"execution_count":131,"outputs":[{"output_type":"stream","text":["2021-01-24 12:45:59.458469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0124 12:46:02.642895 139749049919360 model_lib.py:793] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting train_steps: 1000\n","I0124 12:46:02.643161 139749049919360 config_util.py:552] Maybe overwriting train_steps: 1000\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0124 12:46:02.643297 139749049919360 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n","I0124 12:46:02.643395 139749049919360 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0124 12:46:02.643496 139749049919360 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0124 12:46:02.643621 139749049919360 model_lib.py:809] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","I0124 12:46:02.643727 139749049919360 model_lib.py:846] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n","INFO:tensorflow:Using config: {'_model_dir': '{model_dir}', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","I0124 12:46:02.644363 139749049919360 estimator.py:191] Using config: {'_model_dir': '{model_dir}', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n","WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1972700a60>) includes params argument, but params are not passed to Estimator.\n","W0124 12:46:02.645664 139749049919360 model_fn.py:629] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f1972700a60>) includes params argument, but params are not passed to Estimator.\n","INFO:tensorflow:Not using Distribute Coordinator.\n","I0124 12:46:02.646955 139749049919360 estimator_training.py:186] Not using Distribute Coordinator.\n","INFO:tensorflow:Running training and evaluation locally (non-distributed).\n","I0124 12:46:02.647274 139749049919360 training.py:645] Running training and evaluation locally (non-distributed).\n","INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","I0124 12:46:02.647641 139749049919360 training.py:733] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","W0124 12:46:02.657218 139749049919360 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","2021-01-24 12:46:02.668322: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2021-01-24 12:46:02.669412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n","2021-01-24 12:46:02.680603: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2021-01-24 12:46:02.680656: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (86d754765465): /proc/driver/nvidia/version does not exist\n","Traceback (most recent call last):\n","  File \"/content/models/research/object_detection/model_main.py\", line 108, in <module>\n","    tf.app.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/models/research/object_detection/model_main.py\", line 104, in main\n","    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 505, in train_and_evaluate\n","    return executor.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 646, in run\n","    return self.run_local()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 747, in run_local\n","    saving_listeners=saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 349, in train\n","    loss = self._train_model(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1175, in _train_model\n","    return self._train_model_default(input_fn, hooks, saving_listeners)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1201, in _train_model_default\n","    self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1037, in _get_features_and_labels_from_input_fn\n","    self._call_input_fn(input_fn, mode))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1130, in _call_input_fn\n","    return input_fn(**kwargs)\n","  File \"/content/models/research/object_detection/inputs.py\", line 735, in _train_input_fn\n","    params=params)\n","  File \"/content/models/research/object_detection/inputs.py\", line 825, in train_input\n","    model_config, is_training=True).preprocess\n","  File \"/content/models/research/object_detection/builders/model_builder.py\", line 1107, in build\n","    add_summaries)\n","  File \"/content/models/research/object_detection/builders/model_builder.py\", line 583, in _build_faster_rcnn_model\n","    _check_feature_extractor_exists(frcnn_config.feature_extractor.type)\n","  File \"/content/models/research/object_detection/builders/model_builder.py\", line 251, in _check_feature_extractor_exists\n","    'Tensorflow'.format(feature_extractor_type))\n","ValueError: faster_rcnn_resnet152 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"HxRGIJMLQmkH","executionInfo":{"status":"ok","timestamp":1611489508640,"user_tz":0,"elapsed":462,"user":{"displayName":"Leon Yao","photoUrl":"","userId":"15846177251700038630"}},"outputId":"211d368b-dc13-4751-959f-10bf8c395b11"},"source":["pipeline_fname"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/models/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config'"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"code","metadata":{"id":"_tp12R-2Qnsw"},"source":[""],"execution_count":null,"outputs":[]}]}